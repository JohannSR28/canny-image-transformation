<!doctype html>
<html lang="fr">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Canny Camera (No Backend)</title>

    <script src="https://cdn.tailwindcss.com"></script>
    <script async src="https://docs.opencv.org/4.x/opencv.js"></script>
  </head>

  <body class="min-h-screen bg-zinc-950 text-zinc-100">
    <div class="max-w-5xl mx-auto px-4 py-8">
      <!-- Top bar -->
      <div class="flex items-center justify-between gap-4 mb-4">
        <h1 class="text-xl font-semibold">Canny Camera</h1>

        <div class="flex gap-2">
          <button id="startBtn"
            class="rounded-2xl bg-white text-zinc-950 font-semibold px-4 py-2 hover:bg-zinc-200 transition disabled:opacity-50 disabled:cursor-not-allowed">
            Start
          </button>

          <button id="stopBtn"
            class="rounded-2xl border border-zinc-800 px-4 py-2 hover:bg-zinc-900 transition disabled:opacity-50 disabled:cursor-not-allowed">
            Stop
          </button>

          <button id="saveBtn"
            class="rounded-2xl border border-zinc-800 px-4 py-2 hover:bg-zinc-900 transition disabled:opacity-50 disabled:cursor-not-allowed">
            Enregistrer
          </button>
        </div>
      </div>

      <!-- Two outputs: Original (top) + Canny (bottom) -->
      <div class="rounded-2xl border border-zinc-800 bg-zinc-900/40 p-3">
        <div class="grid gap-3">
          <!-- Original -->
          <div class="rounded-2xl border border-zinc-800 bg-zinc-950/40 p-2">
            <p class="text-xs text-zinc-400 mb-2">Original (miroir)</p>
            <div class="aspect-video rounded-2xl border border-zinc-800 bg-zinc-950/40 flex items-center justify-center overflow-hidden">
              <canvas id="origCanvas" class="block"></canvas>
            </div>
          </div>

          <!-- Canny -->
          <div class="rounded-2xl border border-zinc-800 bg-zinc-950/40 p-2">
            <p class="text-xs text-zinc-400 mb-2">Canny (traits)</p>
            <div class="aspect-video rounded-2xl border border-zinc-800 bg-zinc-950/40 flex items-center justify-center overflow-hidden">
              <canvas id="cannyCanvas" class="block"></canvas>
            </div>
          </div>
        </div>

        <!-- Controls -->
        <div class="mt-4 grid md:grid-cols-3 gap-4">
          <div>
            <label class="text-sm text-zinc-300">Low: <span id="lowVal">80</span></label>
            <input id="low" type="range" min="0" max="255" value="80" class="w-full" />
          </div>

          <div>
            <label class="text-sm text-zinc-300">High: <span id="highVal">180</span></label>
            <input id="high" type="range" min="0" max="255" value="180" class="w-full" />
          </div>

          <div>
            <label class="text-sm text-zinc-300">Blur: <span id="blurVal">5</span></label>
            <input id="blur" type="range" min="1" max="21" step="2" value="5" class="w-full" />
            <p class="text-xs text-zinc-500 mt-1">Impairs uniquement (1,3,5…)</p>
          </div>
        </div>

        <div class="mt-3 flex items-center justify-between gap-3">
          <p id="status" class="text-sm text-zinc-400">Chargement OpenCV…</p>

          <div class="flex items-center gap-3">
            <label class="text-sm text-zinc-300 flex items-center gap-2 cursor-pointer select-none">
              <input id="invert" type="checkbox" class="scale-110" checked />
              Inverser (fond blanc)
            </label>

            <label class="text-sm text-zinc-300 flex items-center gap-2 cursor-pointer select-none">
              <input id="hq" type="checkbox" class="scale-110" />
              HQ
            </label>
          </div>
        </div>
      </div>

      <!-- Hidden video + processing canvases -->
      <video id="video" class="hidden" playsinline></video>
      <canvas id="inCanvas" class="hidden"></canvas>
      <canvas id="mirrorCanvas" class="hidden"></canvas>
    </div>

    <script>
      // Buttons / status
      const startBtn = document.getElementById("startBtn");
      const stopBtn = document.getElementById("stopBtn");
      const saveBtn = document.getElementById("saveBtn");
      const statusEl = document.getElementById("status");

      // Controls
      const low = document.getElementById("low");
      const high = document.getElementById("high");
      const blur = document.getElementById("blur");
      const lowVal = document.getElementById("lowVal");
      const highVal = document.getElementById("highVal");
      const blurVal = document.getElementById("blurVal");
      const invert = document.getElementById("invert");
      const hq = document.getElementById("hq");

      // Video + canvases
      const video = document.getElementById("video");
      const inCanvas = document.getElementById("inCanvas");        // raw frame
      const mirrorCanvas = document.getElementById("mirrorCanvas");// mirrored frame (for display + processing)
      const origCanvas = document.getElementById("origCanvas");    // output original
      const cannyCanvas = document.getElementById("cannyCanvas");  // output canny

      // State
      let cvReady = false;
      let stream = null;
      let running = false;

      // UI labels
      low.addEventListener("input", () => (lowVal.textContent = low.value));
      high.addEventListener("input", () => (highVal.textContent = high.value));
      blur.addEventListener("input", () => (blurVal.textContent = blur.value));

      // OpenCV ready
      function waitForCV() {
        if (typeof cv !== "undefined" && cv.Mat) {
          cvReady = true;
          statusEl.textContent = "Prêt ✅";
          startBtn.disabled = false;
          stopBtn.disabled = true;
          saveBtn.disabled = true;
          return;
        }
        setTimeout(waitForCV, 100);
      }
      startBtn.disabled = true;
      stopBtn.disabled = true;
      saveBtn.disabled = true;
      waitForCV();

      function pickConstraints() {
        if (hq.checked) {
          return { video: { facingMode: "user", width: { ideal: 1280 }, height: { ideal: 720 } }, audio: false };
        }
        return { video: { facingMode: "user", width: { ideal: 640 }, height: { ideal: 360 } }, audio: false };
      }

      async function startCamera() {
        if (!cvReady) return (statusEl.textContent = "Chargement OpenCV…");
        if (running) return;

        statusEl.textContent = "Demande caméra…";

        try {
          stream = await navigator.mediaDevices.getUserMedia(pickConstraints());
          video.srcObject = stream;
          await video.play();

          const vw = video.videoWidth || 640;
          const vh = video.videoHeight || 360;

          // Set canvas sizes
          inCanvas.width = vw; inCanvas.height = vh;
          mirrorCanvas.width = vw; mirrorCanvas.height = vh;

          origCanvas.width = vw; origCanvas.height = vh;
          cannyCanvas.width = vw; cannyCanvas.height = vh;

          running = true;
          startBtn.disabled = true;
          stopBtn.disabled = false;
          saveBtn.disabled = false;
          statusEl.textContent = "Live ✅";

          renderLoop();
        } catch (e) {
          statusEl.textContent = "Caméra refusée / indisponible";
          running = false;
          startBtn.disabled = false;
          stopBtn.disabled = true;
          saveBtn.disabled = true;
        }
      }

      function stopCamera() {
        running = false;
        startBtn.disabled = false;
        stopBtn.disabled = true;
        saveBtn.disabled = true;

        if (stream) {
          stream.getTracks().forEach((t) => t.stop());
          stream = null;
        }

        // Clear outputs
        origCanvas.getContext("2d").clearRect(0, 0, origCanvas.width, origCanvas.height);
        cannyCanvas.getContext("2d").clearRect(0, 0, cannyCanvas.width, cannyCanvas.height);

        statusEl.textContent = cvReady ? "Prêt ✅" : "Chargement OpenCV…";
      }

      // Mirror a frame: draw video to inCanvas then mirrored to mirrorCanvas
      function drawMirroredFrame() {
        // raw
        const inCtx = inCanvas.getContext("2d", { willReadFrequently: true });
        inCtx.drawImage(video, 0, 0, inCanvas.width, inCanvas.height);

        // mirror
        const mCtx = mirrorCanvas.getContext("2d", { willReadFrequently: true });
        mCtx.save();
        mCtx.clearRect(0, 0, mirrorCanvas.width, mirrorCanvas.height);
        mCtx.translate(mirrorCanvas.width, 0);
        mCtx.scale(-1, 1);
        mCtx.drawImage(inCanvas, 0, 0);
        mCtx.restore();
      }

      // Main loop: show mirrored original + canny computed from mirrored
      function renderLoop() {
        if (!running) return;

        // Get frame and mirror it
        drawMirroredFrame();

        // Display mirrored original (top)
        origCanvas.getContext("2d").drawImage(mirrorCanvas, 0, 0);

        // thresholds safety
        const lowT = Math.min(parseInt(low.value, 10), parseInt(high.value, 10));
        const highT = Math.max(parseInt(low.value, 10), parseInt(high.value, 10));
        const k = parseInt(blur.value, 10);

        try {
          // Process mirrored frame with OpenCV
          const src = cv.imread(mirrorCanvas); // RGBA
          const gray = new cv.Mat();
          cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

          const blurred = new cv.Mat();
          cv.GaussianBlur(gray, blurred, new cv.Size(k, k), 0);

          const edges = new cv.Mat();
          cv.Canny(blurred, edges, lowT, highT);

          if (invert.checked) {
            cv.bitwise_not(edges, edges);
          }

          cv.imshow(cannyCanvas, edges);

          src.delete(); gray.delete(); blurred.delete(); edges.delete();
        } catch (e) {
          statusEl.textContent = "Erreur traitement";
          stopCamera();
          return;
        }

        // ~30fps if not HQ
        if (!hq.checked) {
          setTimeout(() => requestAnimationFrame(renderLoop), 33);
        } else {
          requestAnimationFrame(renderLoop);
        }
      }

      // Save: one PNG that contains both images (original + canny)
      function saveBoth() {
        if (!running) return;

        const w = origCanvas.width;
        const h = origCanvas.height;

        const out = document.createElement("canvas");
        out.width = w;
        out.height = h * 2;

        const ctx = out.getContext("2d");

        // Background (optional)
        ctx.fillStyle = "#000";
        ctx.fillRect(0, 0, out.width, out.height);

        // Draw original on top, canny on bottom
        ctx.drawImage(origCanvas, 0, 0, w, h);
        ctx.drawImage(cannyCanvas, 0, h, w, h);

        // Small labels (optional but tiny)
        ctx.fillStyle = "rgba(255,255,255,0.8)";
        ctx.font = "20px sans-serif";
        ctx.fillText("Original (miroir)", 16, 30);
        ctx.fillText("Canny", 16, h + 30);

        const url = out.toDataURL("image/png");
        const a = document.createElement("a");
        a.href = url;
        a.download = `canny_capture_${Date.now()}.png`;
        document.body.appendChild(a);
        a.click();
        a.remove();
      }

      // Events
      startBtn.addEventListener("click", startCamera);
      stopBtn.addEventListener("click", stopCamera);
      saveBtn.addEventListener("click", saveBoth);

      // Toggle HQ while running => restart to apply constraints
      hq.addEventListener("change", async () => {
        if (!running) return;
        stopCamera();
        await startCamera();
      });
    </script>
  </body>
</html>
